spark-uri = "local[*]"

sparknlp.settings.overrideConfigPath = "sparknlp.conf"

common {
  default-steps = [
    "all"
  ]
  output-format = "parquet"
  output = "gs://ot-snapshots/literature/20210420"
}

# this is a temporal lut for pmcid to pmid
# http://ftp.ebi.ac.uk/pub/databases/pmc/DOI/PMID_PMCID_DOI.csv.gz
processing {
  epmcids {
    format = "csv"
    path = "gs://ot-snapshots/otar025-epmc/PMID_PMCID_DOI.csv.gz"
    options = [
      {k: "header", v: "true"}
      {k: "inferSchema", v: "true"}
    ]
  }
  diseases {
    format = "parquet"
    path = "gs://ot-snapshots/otar025-epmc/diseases"
  }

  targets {
    format = "parquet"
    path = "gs://ot-snapshots/otar025-epmc/targets"
  }
  drugs {
    format = "parquet"
    path = "gs://ot-snapshots/otar025-epmc/molecule"
  }
  epmc {
    format = "json"
    path = "gs://ot-snapshots/otar025-epmc/20210408/"
  }
  outputs = {
    raw-evidence {
      format = ${common.output-format}
      path = ${common.output}"/rawEvidence"
    }
    cooccurrences {
      format = ${common.output-format}
      path = ${common.output}"/cooccurrences"
    }
    matches {
     format = ${common.output-format}
     path = ${common.output}"/matches"
    }
    literature-index {
      format = "json"
      path = ${common.output}"/literatureIndex"
    }
  }
}

embedding {
  num-synonyms = 50
  model-configuration {
    window-size = 5
    num-partitions = 8
    max-iter = 3
    min-count = 1
    step-size = 0.025
  }
  input = ${processing.outputs.matches}
  outputs = {
    wordvec {
     format = ${common.output-format}
     path = ${common.output}"/W2VModel"
    }
    wordvecsyn {
     format = ${common.output-format}
     path = ${common.output}"/W2VSynonyms"
    }
  }
}

vectors {
  input = ${embedding.outputs.wordvec.path}
  output {
    format = "json"
    path = ${common.output}"/vectors"
  }
}